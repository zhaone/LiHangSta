# 提升方法
提升放的基本思想就是**三个臭皮匠顶个诸葛亮**：假设我们有多个能力比较弱的分类器，那么可以通过某些方法对这些弱分类器的结果进行组合得出最后的判断。所以对提升方法来说主要有**两个问题**需要回答：
- 每一轮如何改变训练数据的权值或者概率分布
- 如何将弱分类器组合成强分类器
## Adaboost
**基本思想**：对第一个问题，adaboost提高被前一轮弱分类器错误分类的样本的权值，降低分类正确样本的权值，这样下一轮分类器会更“关照”被错误分类的样本；对于第二个问题，adaboost采用弱分类器加权表决的方式，分类误差率小的分类器的权值大，分类误差率大的权值小。
### 算法
二分类数据集为
$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$
其中，实例$x_i \in x \subseteq \mathrm{R}^n$，标记$y_i \in \gamma=\{-1,+1\}$，则adaboost算法如下：
1. 初始化训练数据的权值分布
$$
D_{1}=\left(w_{11}, \cdots, w_{1 i}, \cdots, w_{1 N}\right), \quad w_{1 i}=\frac{1}{N}, \quad i=1,2, \cdots, N
$$
即首先将所有数据的权值设为相同，保证模型首先从原始数据学校一个基本分类其。
2. 对$M=1,2,...,m$，执行以下步骤
	a. 使用权值分布$D_m$的训练数据学习，得到基本分类器
$$
G_{m}(x) : \mathcal{X} \rightarrow\{-1,+1\}
$$
即用更新完权值之后的数据对基本模型进行训练，得到一个新的基本分类器$G_m$
	b. 计算$G_m(x)$在数据集上的分类误差
$$
e_{m}=P\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)=\sum_{i=1}^{N} w_{m i} I\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)
$$
这个误差是一个带权的误差，也很好理解，就是分类错误的样本的权值之和
	c. 计算$G_m(x)$的系数
$$
\alpha_{m}=\frac{1}{2} \log \frac{1-e_{m}}{e_{m}}
$$
显然$0<e_m<1$，$e_m<0.5$时，$\alpha_m$为负，这有点好玩，就像如果你的判断准确率还不到一半，那总体来讲其实你对分类准确率做的是负贡献，那么我不相信你。。。这一步其实就是在确定表决中分类器的权值
	d. 更新数据集的权值分布
$$
\begin{array}{c}{D_{m+1}=\left(w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1, N}\right)} \\ {w_{m+1, i}=\frac{w_{m i}}{Z_{m}} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right), \quad i=1,2, \cdots, N} \\ Z_{m}=\sum_{i=1}^{N} w_{m i} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right) \end{array}
$$
观察先第二个式子，显然分类错误（正确时）时，$y_iG_m(x_i)=1$为$-1(1)$，所以
$$
w_{m+1, i}=\left\{\begin{array}{ll}{\frac{w_{m i}}{Z_{m}} \mathrm{e}^{-\alpha_{m}},} & {G_{m}\left(x_{i}\right)=y_{i}} \\ {\frac{w_{m i}}{Z_{m}} \mathrm{e}^{\alpha_{m}},} & {G_{m}\left(x_{i}\right) \neq y_{i}}\end{array}\right.
$$
据李说，按照这种方法被$G_m(x)$误分类的样本权值得以扩大，但是我觉得**这个式子有问题**。被分类错误即$G_{m}\left(x_{i}\right) \neq y_{i}$，这时$e^{\alpha_m}$是否大于1应该取决于$\alpha_m$的大小，当$\alpha_m$大于0时，权值扩大；当$\alpha_m$小于0时，权值缩小。。。是他写错了吗，到底是嘛意思
最后一个式子使得$D_{m+1}$成为一个概率分布，这没有什么问题
3. 构建基本分类器的线性组合
$$
f(x)=\sum_{m=1}^{M} \alpha_{m} G_{m}(x)
$$
得到最终的分类器
$$
G(x)=\operatorname{sign}(f(x))=\operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right)
$$
这是一个加法表决模型，最后的判断结果是$sign(f(x))$给出的
### 问题
对于上面的算法，有几个地方不理解。
#### 训练策略问题
算法中描述使用带权值的数据集$D_m$进行基本分类器的训练，那么问题来了。李书中的基本分类器都比较简单，基本都是采用树桩决策树，直接判断分类器的带权分类准确率大小，从而确定分类器（相当于训练了分类器）。但是**一些基本分类器，比如说cart决策树有自己的训练策略（例如基尼系数最小），训练基本分类器时权值是采用1. 步骤2.b的带权分类误差最小为策略能，还是采用2. 自己的训练策略呢？**
如果采用步骤2.b的带权分类误差最小，则权值是能够用得上，但是。。。根据这个分类策略怎么训练基本模型呢，这并不是某些基本模型的损失函数啊；如果采用基本模型的训练方式，权值又用不上了。。。
#### 权值更新问题
如上面所说，显然本分类错误的样本权值不一定增大，如果本分类器分类准确率大于$0.5$才会增大，这和李说的不符吧

### 回答
对于第一个问题，emmm，B乎上有人回答过[这个问题](https://www.zhihu.com/question/26957827)，主要有以下几点
1. 首先训练基本分类器采用的是自己本身的训练方法
2. 使用权值大概又两种方法
	a. 修改基本分类器训练代码，使得其支持带权数据训练。例如拿LR来说，如果原来的损失函数是$cost(x)$，那么现在应该是$w*cost(x)$，又例如树模型，则需要修改信息增益或者gini的公式，引入权值
	b. 对训练样本，进行bootstrap抽样，每次抽样的概率等于样本权值
3. 一般弱分类器的训练方法都比较简单，引入权值也比较方便。一些强分类器一般不会用作adaboost的基本分类器，因为太强了，第一次产生的分类器错误率上已经达到极限，使后面的分类器起不到效果，或者说分类器的差异性太小

第二个问题暂时没找找到答案^_^|||
## 前向分步算法（最重要）
### 加法模型
adaboost其实就是个加法模型，加法模型满足以下形式
$$
f(x)=\sum_{m=1}^{M} \beta_{m} b\left(x ; \gamma_{m}\right)
$$
其中$b(x;\gamma_m)$为基函数，可以理解为分类器模型，$\gamma_{m}$为基函数参数，可以理解为模型参数；$\beta_m$为基函数的权，可以理解为基本分类器加权表决的权。
在给定训练数据及损失函数$L(Y,f(X))$的条件下，学习加法模型$f(x)$成为经验风险极小化即损失函数极小化问题：
$$
\min _{\beta_{m}, \gamma_{m}} \sum_{i=1}^{N} L\left(y_{i}, \sum_{m=1}^{M} \beta_{m} b\left(x_{i} ; \gamma_{m}\right)\right)
$$
显然这玩意不是很好算，因为同时有m个模型。
前向分布算法的思想是，既然同时算m个模型比较难，那我每次学一个基函数和它的系数，逐步优化目标函数。具体的，每步只优化如下损失函数：
$$
\min _{\beta, \gamma} \sum_{i=1}^{N} L\left(y_{i}, \beta b\left(x_{i} ; \gamma\right)\right)
$$
其基本算法描述如下：
1. 初始化$f_0(x)=0$
2. 对$m=1,2,...,M$
	a. 极小化损失函数
$$
\left(\beta_{m}, \gamma_{m}\right)=\arg \min _{\beta, \gamma} \sum_{i=1}^{N} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+\beta b\left(x_{i} ; \gamma\right)\right)
$$
的到参数$\beta_{m}, \gamma_{m}$
	b. 更新
$$
f_{m}(x)=f_{m-1}(x)+\beta_{m} b\left(x ; \gamma_{m}\right)
$$
即加上新的加权基函数
3. 得到加法模型

$$
f(x)=f_{M}(x)=\sum_{m=1}^{M} \beta_{m} b\left(x ; \gamma_{m}\right)
$$
### 前向分步算法与adaboost
为了说明adaboost是一种前向分布算法，需要说明第$m$步adaboost算法中给出的$\alpha_m$和$G_m(x)$就是前向分布算法中的最优$\beta_m$和$b(x,\gamma_m)$，其中损失函数为：
$$
L(y,f(x))=exp[-yf(x)]
$$
即证明：
$$
\left(\alpha_{m}, G_{m}(x)\right)=\arg \min _{\alpha, G} \sum_{i=1}^{N} \exp \left[-y_{i}\left(f_{m-1}\left(x_{i}\right)+\alpha G\left(x_{i}\right)\right)\right]
$$
这在书中已经详细介绍了，在此不再赘述。
### 问题
还是主要关于$\alpha$的问题。再证明adaboost是一种前向分布算法时，书中说对任意$\alpha>0$得出了$G_m(x)$是最优的结论，但是根据公式5，显然并不是所有$\alpha$都是大于0的。。。这里我没有搞懂

## 提升树模型(GBDT )
提升树是加法模型的一种，即其基函数为决策树，决策树有分类决策树和回归树。二分类决策树就是adaboost的一个特例；这里主要介绍以回归树为基函数的提升树模型。提升树的算法采用上述的前向分步算法，其主要区别在于使用的损失函数（平方损失函数，指数损失函数or一般的损失函数）
### 提升树算法
采用平方损失函数的提升树很好理解，在这不再赘述，主要说下以普通函数为损失函数的提升树的前向分步算法。
当以普通函数为损失函数时，其残差不是很好算，此时用
$$
r_{m i}=-\left[\frac{\partial L\left(y_{i}, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}
$$
来表示残差的估计值。我个人不知道具体怎么得出这个式子的，只对这个式子为什么能反映残差大小有个感性的认识。
要想得到小的$L$，我们需要该偏导为0，偏导数越大，表示此$f(x_i)$想要到0需要变动的幅度越大，越不接近最优，所以残差的绝对值就比较大；同时，若偏导>0，则残差小于0，想象下凸函数的图像即可知，偏导>0时，$f(x_i)$在最优函数$f$的左侧，所以残差为负。以平方误差函数为例，其对$f(x_i)$求偏导，值为$-(y_i-f(x_i))$，则$r_i=y_i-f(x_i)$，和书中给出的平方误差函数求残差的值一模一样。
### 问题
Emmm，但是有些损失函数的偏导没有这种性质，比如万一一个损失函数长这个样子：

![标准正态分布](https://images2015.cnblogs.com/blog/380252/201510/380252-20151022225551895-1308990460.png)

若$f(x_i)=-5$,此时偏导数几乎为0，估计出来的残差很小，但实际上$f(x_i)$离最佳值其实很远，这是个问题
## xgboost

[论文大大在此](https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf)。。。可惜我看到博客最后找到论文。。。DT

最近xgboost挺火的哈，有个博客讲的不错，见[链接](https://blog.csdn.net/a1b2c3d4123456/article/details/52849091)。这其实就是一种提升树，主要特点在于：
- 训练算法是前向分步算法（也是一个加法模型）
- 基函数就是回归树
- 目标函数通过二阶泰勒展开式做近似 
- 损失函数不仅考虑误差，而且定义了树的复杂度，并应用到目标函数中 ，放置了过拟合
- 分裂结点处通过结构打分和分割损失动态生长（其实是一种贪心算法）
- 分裂结点的候选集合通过一种分布式Quantile Sketch得到（算得快）
### 目标函数
xgboost的目标函数张下面这个样子：
$$
\begin{array}{l}{\mathcal{L}(\phi)=\sum_{i} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{k} \Omega\left(f_{k}\right)}+c \\ {\text { where } \Omega(f)=\gamma T+\frac{1}{2} \lambda\|w\|^{2}}\end{array}
$$
其中$f_k$为第k轮要加到模型中的树，$\hat{y}_{i}$为当前模型（k个树）的回归预测结果，$y$是样本的标签，$l()$函数为度量当前模型误差的函数，$\Omega(f)$度量整个模型的复杂度，其中$T$为树叶子节点个数，$w$为所有叶子节点预测值组成的向量，$c$就是一常量。

![模型复杂度函数](https://img-blog.csdn.net/20161018144705051)

显然，该目标函数同时考虑了训练集的误差和树的复杂度，防止过拟合。只是在这里我**不是很能理解权值平方和**有什么意义，能够反映模型复杂度吗？

### 目标函数化简

根据上面的前向分步算法，第t轮的目标函数可以写成
$$
O b j^{(t)}=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\sum_k^t\Omega\left(f_k\right)+c
$$
$c$是个定值，同时由于$\sum_k^t\Omega\left(f_k\right)=\sum_k^{t-1}\Omega\left(f_k\right)+\Omega\left(f_t\right)$，$\sum_k^{t-1}\Omega\left(f_k\right)$在前面$t-1$个树已经确定的情况下，也是个定值，这两项都对目标函数优化没什么卵用，所以目标函数可以写成
$$
O b j^{(t)}=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_t\right)
$$
那么现在的目标就是通过优化$f_t$使得目标函数最小。这里用了一个泰勒二阶展开的技巧对上述目标函数进行化简（一般提升树只用了一阶导数），根据泰勒展开有：
$$
f(x+\Delta x) \simeq f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}
$$

在目标函数的$l$函数中，我们认为$y_i,\hat{y_i}^{(t-1)}$为$x$，$f_t(x_i)$为$\Delta x$，则目标函数可以**近似**记为
$$
O b j^{(t)} \simeq \sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)
$$
其中$g_{i}=\partial_{\hat{y}_i^{(t-1)}} l\left(y_{i}, \hat{y_i}^{(t-1)}\right), \quad h_{i}=\partial_{\hat{y_i}^{(t-1)}}^{2} l\left(y_{i}, \hat{y_i}^{(t-1)}\right)$，即$g_i,h_i$分别为一二阶段导数。显然$l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)$是个定值，对目标函数优化也没什么意义，所以继续简写为
$$
O b j^{(t)} \left[\simeq g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)
$$
现在假设对于回归树$f_t$，我们已经完成了构建，将输入划分为$T$个集合$I_j$，$I_j$对应的输出值为$w_j$，那么目标函数可以接着写成
$$
Obj^{(t)} \simeq \sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T
$$
记$G_j=\sum_{i \in I_{j}} g_{i},H_j=\sum_{i \in I_{j}}h_i$，则目标函数最终为
$$
Obj^{(t)} \simeq \sum_{j=1}^{T}\left[G_{j} w_{j}+\frac{1}{2}\left(H_{j}+\lambda\right) w_{j}^{2}\right]+\gamma T
$$
对$w_j$求导得到
$$
w_{j}^{*}=-\frac{G_{j}}{H_{j}+\lambda}
$$
则最终的目标函数值为
$$
O b j=-\frac{1}{2} \sum_{j=1}^{T} \frac{G_{j}^{2}}{H_{j}+\lambda}+\gamma T \sim -\sum_{j=1}^{T} \frac{G_{j}^{2}}{H_{j}+\lambda}+\gamma T
$$
式(28)给出了树结构的目标函数值，越小表明该树越优，由于$\gamma$是自己设的参数，所以参数$-\frac{1}{2}$没啥意义；同时，式(27)给出了该树结构下，各个叶子节点的回归值。

### 树的构建

由式28已经给出了度量树优良程度的公式，其中$G_j,H_j$只依赖于数据$x_i$上一轮得到的模型输出$\hat{y_i}^{(t-1)}$的一二阶倒数，可以直接遍历一遍数据，将所有的$g_i,h_i$直接求出来，对不同的分割方式，供计算式27，28使用，而不用每次分割都计算一次。

如何构建基本上是个单个回归树的问题，首先介绍一个贪心算法解决的方案

#### 贪心
首先说明，这里的回归树是一个二叉树，即每个节点最多就分成两个节点。那么对一个树节点，我们有两种选择，第一种是不分了，第二种是找一种好的拆分方式。
假设我们将一个节点分为了$L,R$两个集合，那么未分之前，该节点对目标函数的贡献是
$$
-\frac{G_{L+R}^{2}}{H_{L+R}+\lambda}+\gamma=-\frac{G_{L}^{2}+G_{R}^{2}}{H_{L}+H_{R}+\lambda} + \gamma
$$
分裂之后，LR两个节点对目标函数的贡献为
$$
-\frac{G_{L}^{2}}{H_{L}+\lambda}-\frac{G_{R}^{2}}{H_{R}+\lambda}+2\gamma
$$
我们想要目标函数尽可能小，分裂一个节点对目标函数的变化为
$$
-\frac{G_{L}^{2}}{H_{L}+\lambda}-\frac{G_{R}^{2}}{H_{R}+\lambda}+2\gamma +\frac{G_{L}^{2}+G_{R}^{2}}{H_{L}+H_{R}+\lambda} - \gamma = \frac{G_{L}^{2}+G_{R}^{2}}{H_{L}+H_{R}+\lambda}-\frac{G_{L}^{2}}{H_{L}+\lambda}-\frac{G_{R}^{2}}{H_{R}+\lambda} + \gamma
$$

所以，我们的目的是**找出一个节点的某种分割方式，使式32尽可能小**。

> 可以先说下分割什么时候停止：1. 如果所有节点的所有分割方式，式子32都是大于0的，说明不存在让目标函数更小的分割了，此时停止，$f_t$构造完成了；2. 可以自己添加条件，比如说当叶子节点数目大于阈值时就停止（不想要树太复杂）

注意，上述方法是一种贪心算法，只寻找下一步使目标函数最小的分割方式，并不保证得到的树是最好的，自己分析下就知道。

#### 分裂算法

经过上述贪心算法的分析，我们需要找出一个算法，使得式32尽可能小。论文里面给出了四个方法，分别是暴力搜索、近似算法和Weighted Quantile Sketch和Sparsity-aware Split Finding

##### 暴力搜索

当然，你可以**直接暴力搜索**，即对每个节点的每个特征的每个值都算一遍式32，anyway，忽略耗时和数据量的话，这总能得到最好的正确答案。

##### 近似算法

近似方法通过特征的分布，按照百分比确定一组候选分裂点，通过遍历所有的候选分裂点来找到最佳分裂点。 什么意思呢，就是说先观察下所有可以分裂的叶子节点的数据分布，找一个比较好的叶子节点，只对该节点进行式32的计算。例如，我有两个叶子节点（连续值），我会选择其数据集合能够用超平面分的更开的那个节点来作为本次的分裂节点。。。突然感觉有点像算基尼系数

##### Weighted Quantile Sketch

##### Sparsity-aware Split Finding

TODO分裂的算法留着研究